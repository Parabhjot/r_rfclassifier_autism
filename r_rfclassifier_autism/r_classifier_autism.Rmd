---
title: "Random Forest Classifer: Classifying Autism Spectrum Disorder"
author: "Parabhjot Deol"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document: 
    number_sections: TRUE
    code_folding: hide
    toc: yes
    toc_float: 
      toc_collapsed: true
    theme: readable
---

```{r  "setup", include=FALSE}  
knitr::opts_chunk$set(echo = TRUE, message=FALSE, error=FALSE, warning=FALSE, comment=NA)
pacman::p_load(xray, magrittr, psych, DT, car, DescTools, MASS, tidyverse, caret)
```

Included below is a code chunk used to read the data set.  

```{r}
df <- read.csv("data/autism_data.csv")
```

# Data Cleaning Steps

## Look at the first few rows of data 

```{r}
headTail(df) %>% 
  datatable(rownames = TRUE, filter="top", options = list(pageLength = 10, scrollX=T)) %>% 
  formatRound(columns=c(1:21), digits=0 )
```

## Look at structure of dataset 
```{r}
str(df)
```

## Find all variables with NAs

```{r}
na_count <-sapply(df, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
```

## Look at all the unique values that each variable takes on. 

```{r}
for (i in c(1:ncol(df))) {
  print(colnames(df)[i])
  print(table(df[,i], useNA="always"))
}
```

## Convert variables to numeric 

Age was interpretted as a factor when loading the dataset, convert this to numeric.  

```{r}
df$age <- as.numeric(as.character(df$age))
```

## Convert to factors 

We see most of the score variables are numeric and should be converted to factor.  

```{r}
df <- within(df, {
  A1_Score <- factor(A1_Score)
  A2_Score <- factor(A2_Score)
  A3_Score <- factor(A3_Score)
  A4_Score <- factor(A4_Score)
  A5_Score <- factor(A5_Score)
  A6_Score <- factor(A6_Score)
  A7_Score <- factor(A7_Score)
  A8_Score <- factor(A8_Score)
  A9_Score <- factor(A9_Score)
  A10_Score <- factor(A10_Score)
})
```

## Use the x-ray package to create plots to visualize the data 

Now that the data is in the correct format, we can visualize it using the x-ray package.  

```{r}
distributions( df[ , -c(1) ] ) 
```

## Updates to make  

After all exploratory data analysis, we notice the following updates to make:  
- Age has an outlier point and some observations have age = "?"   
- 95 observations have ethnicity = "?"   
- Country of res has too many low count groups   
- The variable age_desc has no value since all observations fall into a single category    
- Relation has 95 observations = "?"    
- Take out variables that are not logical such as "used_app_before" and "relation" of the person who filled out the form  

We update the df below:  

```{r}
df_reduced <- df[ , !(names(df) %in% "contry_of_res")]
df_reduced <- df_reduced[ , !(names(df_reduced) %in% "used_app_before")]
df_reduced <- df_reduced[ , !(names(df_reduced) %in% "relation")]
df_reduced <- df_reduced[ , !(names(df_reduced) %in% "age_desc")]
df_reduced<- df_reduced[ , !(names(df_reduced) %in% "result")]
df_reduced <- df_reduced[ , !(names(df_reduced) %in% "ethnicity")]
df_reduced <- df_reduced[!(df_reduced$age>150),]
df_reduced <- na.omit(df_reduced)
```

# Random Forest Classifier

Used this guide: https://www.r-bloggers.com/how-to-implement-random-forests-in-r/   

## Split the data into training and testing sets   

```{r}
set.seed(123)
training.samples <- df_reduced$Class.ASD %>% createDataPartition(p = 0.7, list = FALSE)
df_train <- df_reduced[training.samples, ]
df_test <- df_reduced[-training.samples, ]
```

## Load required Libraries 

```{r}
pacman::p_load(randomForest, caret, e1071)
```

## Create a Random Forest model with default parameters

```{r}
model1 <- randomForest(Class.ASD ~ ., data = df_train, importance = TRUE)
model1
```

We can fine tune parameters of Random Forest model by:  
1. Changing the number of trees (ntree)   
2. Changing the number of variables randomly sampled at each stage (mtry)  

Ntree: Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.  

Mtry: Number of variables randomly sampled as candidates at each split. The default values are different for classification (sqrt(p) where p is number of variables in x) and regression (p/3)  

## Change model parameters

The model below was run a few times with different parameters and updated using the results from further analyses below.   

```{r}
model2 <- randomForest(Class.ASD ~ ., data = df_train, 
                       ntree = 1500, mtry = 3, importance = TRUE)
model2
```

When mtry is increased to 1,500, error rate is reduced. We will now predict on the train dataset first and then predict on validation dataset.  

## Test on the the train set 

```{r}
predTrain <- predict(model2, df_train, type = "class")
# Checking classification accuracy
mean(predTrain == df_train$Class.ASD)  
table(predTrain, df_train$Class.ASD)  
```

## See what variables are the most important  

```{r}
importance(model2)        
varImpPlot(model2)  
```

## Test on the testing set  

```{r}
predValid <- predict(model2, df_test, type = "class")
# Checking classification accuracy
mean(predValid == df_test$Class.ASD)   
table(predValid,df_test$Class.ASD)
```

Model 2 performed well on the training set with `r mean(predTrain == df_train$Class.ASD)*100`% accuracy, and also achieved `r mean(predValid == df_test$Class.ASD)*100`% accuracy on the testing set.   

## Using a loop to identify the right mtry for model and input into the model above.   

```{r}
a=c()
for (i in 1:20) {
  model3 <- randomForest(Class.ASD ~ ., 
                         data = df_train, ntree = 1500, 
                         mtry = i, importance = TRUE)
  predValid <- predict(model3, df_test, type = "class")
  a[i] = mean(predValid == df_test$Class.ASD)
}
 
a
 
plot(1:20,a)
```

The graph shows us what the accuracy of the model is at each mtry simulation. We see that mtry of 3 is the one used in model 2 above and it produces the best model.  

## Conclusions 

That is all in my attempt to use a random forest classifier. The model created appears to have good accuracy, but I am uncertain of the results because I do not have a good understanding of the data set variables. I might be including variables that will not be available until after the diagnosis.     